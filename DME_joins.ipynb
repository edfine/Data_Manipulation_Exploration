{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation and Exploration\n",
    "\n",
    "## Agenda:\n",
    "- Augmenting your data, collect and prepare both proprietary and public datasets for AI/ML algorithms\n",
    "- Using Pandas to tidy your data\n",
    "- Joins / Merge\n",
    "- Apply\n",
    "- Map\n",
    "\n",
    "## Augmenting your data -Thinking like a data scientist\n",
    "\n",
    "Q: Do other internal departments have data that you can use? \n",
    "\n",
    "\n",
    "### Public Data (3rd party) can augment Proprietary Data (1st party) to make great data products\n",
    "\n",
    "\n",
    "Open data sources\n",
    "1. Weather\n",
    "2. Demographics\n",
    "3. Subscriptions\n",
    "4. Government\n",
    "5. Linked Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources of public data:\n",
    "\n",
    "Programmable Web\n",
    "https://www.programmableweb.com/category/all/apis\n",
    "\n",
    "Weatherunderground etc.\n",
    "\n",
    "\n",
    "Adresses and geocoding\n",
    "https://geocodeapi.com/\n",
    "\n",
    "LoD-data \n",
    "https://lod-cloud.net/\n",
    "\n",
    "There are so many others that finding them can be intimidating.  \n",
    "https://www.quora.com/Where-can-I-find-large-datasets-open-to-the-public\n",
    "https://www.freecodecamp.org/news/https-medium-freecodecamp-org-best-free-open-data-sources-anyone-can-use-a65b514b0f2d/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "Take 5 minutes to look through some of the above resources and come up with interesting, unexpected, useful or funny datasets and then share them in slack.\n",
    "\n",
    "Put your findings in the Slack channel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organising your data\n",
    "\n",
    "### Tidy data\n",
    "\n",
    "See the Tidy Data subfolder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "Review:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joins for data analysts\n",
    "\n",
    "## *Always know what your PRIMARY KEY is before you join or aggregate!*\n",
    "\n",
    "## *Know if your data has duplicates.*  \n",
    "This is so important if you join items. \n",
    "\n",
    "## *Join data sources with the same key or you may duplicates*\n",
    "\n",
    "# Connecting 2 data sources - Types of joins\n",
    "\n",
    "- Inner\n",
    "\n",
    "## Nulls - the scourge of data\n",
    "All other types of joins depend onn null treatment\n",
    "- Left\n",
    "- Right\n",
    "- Outer \n",
    "- Cartesian\n",
    "\n",
    "Joins in Pandas are done with Merge\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Pandas DataFrames in Python\n",
    "Presentation of the DOAJ Articles data\n",
    "For this lesson, we will be using Directory of Open Access Journals (DOAJ) article sample data, available on FigShare. Download this zip and extract it on your working directory on a meaningful location (e.g. create a folder called data/)\n",
    "\n",
    "This data set is a list of published articles. The dataset is stored as .csv (comma separated values) files: each row holds information for a single article, and the columns represent:\n",
    "\n",
    "| Column           | Description                        |\n",
    "|------------------|------------------------------------|\n",
    "| Title            | Title of the article               |\n",
    "| Authors          | Author (or authors)                |\n",
    "| DOI              | DOI                                |\n",
    "| URL              | URL                                |\n",
    "| Subjects         | List of subject key words          |\n",
    "| ISSNs            | ISSNs code                         |\n",
    "| Citation         | Citation information               |\n",
    "| LanguageId       | Language identifier                |\n",
    "| LicenceId        | License identifier                 |\n",
    "| Author_Count     | Number of authors of the article   |\n",
    "| First_Author     | Name of the first author           |\n",
    "| Citation_Count   | Number times it has been cited     |\n",
    "| Day              | Day of publication                 |\n",
    "| Month            | Month of publication               |\n",
    "| Year             | Year of publication                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joins in SQL are done with *join*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many \"real world\" situations, the data that we want to use come in multiple files. We often need to combine these files into a single DataFrame to analyze the data. The pandas package provides various methods for combining DataFrames including merge and concat.\n",
    "\n",
    "In these examples we will be using the same data set, but divided into different tables, which you can download from figshare[https://figshare.com/articles/dataset/LC-articles/3409471]\n",
    "\n",
    "To work through the examples below, we first need to load the articles and journals files into pandas DataFrames. In iPython:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"How do we combine data from multiple sources?\"\n",
    "objectives:\n",
    "- \"Learn how to concatenate two DataFrames together (append one dataFrame to a second dataFrame).\"\n",
    "- \"Learn how to join two DataFrames together using a uniqueID found in both DataFrames.\"\n",
    "- \"Learn how to write out a DataFrame to csv using Pandas.\"\n",
    "\n",
    "keypoints:\n",
    "- \"Concatenating data\"\n",
    "- \"Data output\"\n",
    "- \"Joining DataFrames\"\n",
    "\n",
    "---\n",
    "\n",
    "In many \"real world\" situations, the data that we want to use come in multiple\n",
    "files. We often need to combine these files into a single DataFrame to analyze\n",
    "the data. The pandas package provides [various methods for combining\n",
    "DataFrames](http://pandas.pydata.org/pandas-docs/stable/merging.html) including\n",
    "`merge` and `concat`.\n",
    "\n",
    "In these examples we will be using the same data set, but divided into different\n",
    "tables, which you can download from [figshare](https://figshare.com/articles/LC-articles/3409471)\n",
    "\n",
    "To work through the examples below, we first need to load the articles and\n",
    "journals files into pandas DataFrames. In iPython:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Exercise\n",
    "\n",
    "Can you write a few lines of python to get and extract the files?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "What are the columns of each dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional discussion: Big data in the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example, the join key is the column containing the ISSNs code, called\n",
    "`ISSNs`.\n",
    "\n",
    "Now that we know the fields which links the two data frames, we are almost ready\n",
    "to join our data. However, since there are [different types of joins](http://blog.codinghorror.com/a-visual-explanation-of-sql-joins/),\n",
    "we also need to decide which type of join makes sense for our analysis.\n",
    "\n",
    "## Inner joins\n",
    "\n",
    "The most common type of join is called an *inner join*. An inner join combines\n",
    "two DataFrames based on a join key and returns a new DataFrame that contains\n",
    "**only** those rows that have matching values in *both* of the original\n",
    "DataFrames.\n",
    "\n",
    "Inner joins yield a DataFrame that contains only rows where the value being\n",
    "joins exists in BOTH tables. An example of an inner join, adapted from [this\n",
    "page](http://blog.codinghorror.com/a-visual-explanation-of-sql-joins/) is below:\n",
    "\n",
    "![Inner join -- courtesy of codinghorror.com](http://blog.codinghorror.com/content/images/uploads/2007/10/6a0120a85dcdae970b012877702708970c-pi.png)\n",
    "\n",
    "The pandas function for performing joins is called `merge` and an Inner join is\n",
    "the default option:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "articles_df = pd.read_csv('doajarticlesample/articles.csv',\n",
    "                         keep_default_na=False, na_values=[\"\"])\n",
    "articles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journals_df = pd.read_csv('doajarticlesample/journals.csv')\n",
    "journals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining DataFrames\n",
    "\n",
    "When we concatenated our DataFrames we simply added them to each other -\n",
    "stacking them either vertically or side by side. Another way to combine\n",
    "DataFrames is to use columns in each dataset that contain common values (a\n",
    "common unique id). Combining DataFrames using a common field is called\n",
    "\"joining\". The columns containing the common values are called \"join key(s)\".\n",
    "Joining DataFrames in this way is often useful when one DataFrame is a \"lookup\n",
    "table\" containing additional data that we want to include in the other.\n",
    "\n",
    "NOTE: This process of joining tables is similar to what we do with tables in an\n",
    "SQL database.\n",
    "\n",
    "For example, the `journals.csv` file that we've been working with is a lookup\n",
    "table. This table contains the name of the different journals and a journal ID.\n",
    "The journal ID is unique for each line. These journals are identified in our articles\n",
    "table as well using the unique journal id. Rather than adding the full name of\n",
    "the journal to the articles table, we can maintain the shorter table with the\n",
    "journal information. When we want to access that information, we can create a\n",
    "query that joins the additional columns of information to the articles data.\n",
    "\n",
    "Storing data in this way has many benefits including:\n",
    "\n",
    "1. It ensures consistency in the spelling of journal information (Journal title,\n",
    "  ISSN, Publisher ID).\n",
    "2. It also makes it easy for us to make changes to the journal information once\n",
    "   without having to find each instance of it in the larger article table.\n",
    "3. It optimizes the size of our data.\n",
    "\n",
    "\n",
    "## Joining Two DataFrames\n",
    "\n",
    "To better understand joins, let's grab the first 10 lines of our data as a\n",
    "subset to work with. We'll use the `.head` method to do this. We'll also read\n",
    "in a subset of the journals table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in first 10 lines of articles table\n",
    "articles_sub = articles_df.head(10)\n",
    "\n",
    "# read in first 15 lines of journals table\n",
    "journals_sub = journals_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we want to join with the data in `articles_sub` with the data\n",
    "from `journals_sub`.\n",
    "\n",
    "\n",
    "## Identifying join keys\n",
    "\n",
    "To identify appropriate join keys we first need to know which field(s) are\n",
    "shared between the files (DataFrames). We might inspect both DataFrames to\n",
    "identify these columns. If we are lucky, both DataFrames will have columns with\n",
    "the same name that also contain the same data. If we are less lucky, we need to\n",
    "identify a (differently-named) column in each DataFrame that contains the same\n",
    "information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_inner = pd.merge(left=articles_sub,right=journals_sub, left_on='ISSNs', right_on='ISSNs')\n",
    "# in this case ISSNs is the only column name in both DataFrames, so if we skip left_on\n",
    "# and right_on arguments we would still get the same result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "What's the size of the output data?  Predict it and write it down privately before you explicitely calculate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of an inner join of `articles_sub` and `journals_sub` is a new DataFrame\n",
    "that contains the combined set of columns from `articles_sub` and `journals_sub`. It\n",
    "*only* contains rows that have `ISSNs` that are the same in\n",
    "both the `articles_sub` and `journals_sub` DataFrames. In other words, if a row in\n",
    "`articles_sub` has a value of `ISSNs` that does *not* appear in the `journals_sub`,\n",
    "it will not be included in the DataFrame returned by an\n",
    "inner join.  Similarly, if a row in `journals_sub` has a value of `ISSNs`\n",
    "that does *not* appear in `articles_sub`, that row will not\n",
    "be included in the DataFrame returned by an inner join.\n",
    "\n",
    "The two DataFrames that we want to join are passed to the `merge` function using\n",
    "the *left* and *right* argument. The `left_on='ISSNs'` argument tells `merge`\n",
    "to use the `ISSNs` column as the join key from `articles_sub` (the *left*\n",
    "DataFrame). Similarly , the `right_on='ISSNs'` argument tells `merge` to\n",
    "use the `ISSNs` column as the join key from `journals_sub` (the *right*\n",
    "DataFrame). For inner joins, the order of the *left* and *right* arguments does\n",
    "not matter.\n",
    "\n",
    "The result `merged_inner` DataFrame contains all of the columns from `articles_sub`\n",
    "(`id`, `Month`, `Day`, etc.) as well as all the columns from `journals_sub`\n",
    "(`ISSNs`, `PublisherId`, `Journal_Title`).\n",
    "\n",
    "Notice that `merged_inner` has fewer rows than `articles_sub`. This is an\n",
    "indication that there were rows in `articles_sub` with value(s) for `ISSNs` that\n",
    "do not exist as value(s) for `ISSNs` in `journals_sub`.\n",
    "\n",
    "## Left joins\n",
    "\n",
    "What if we want to add information from `journals_sub` to `articles_sub` without\n",
    "losing any of the information from `articles_sub`? In this case, we use a different\n",
    "type of join called a \"left outer join\", or a \"left join\".\n",
    "\n",
    "Like an inner join, a left join uses join keys to combine two DataFrames. Unlike\n",
    "an inner join, a left join will return *all* of the rows from the *left*\n",
    "DataFrame, even those rows whose join key(s) do not have values in the *right*\n",
    "DataFrame.  Rows in the *left* DataFrame that are missing values for the join\n",
    "key(s) in the *right* DataFrame will simply have null (i.e., `NaN` or `None`) values\n",
    "for those columns in the resulting joined DataFrame.\n",
    "\n",
    "Note: a left join will still discard rows from the *right* DataFrame that do not\n",
    "have values for the join key(s) in the *left* DataFrame.\n",
    "\n",
    "![Left Join](http://blog.codinghorror.com/content/images/uploads/2007/10/6a0120a85dcdae970b01287770273e970c-pi.png)\n",
    "\n",
    "A left join is performed in pandas by calling the same `merge` function used for\n",
    "inner join, but using the `how='left'` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_left = pd.merge(left=articles_sub,right=journals_sub, how='left', left_on='ISSNs', right_on='ISSNs')\n",
    "merged_left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result DataFrame from a left join (`merged_left`) looks very much like the\n",
    "result DataFrame from an inner join (`merged_inner`) in terms of the columns it\n",
    "contains. However, unlike `merged_inner`, `merged_left` contains the **same\n",
    "number of rows** as the original `articles_sub` DataFrame. When we inspect\n",
    "`merged_left`, we find there are rows where the information that should have\n",
    "come from `journals_sub` (i.e., `ISSN-L`, `PublisherId`, `Journal_Title`) is\n",
    "missing (they contain `NaN` values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_left[ pd.isnull(merged_left.PublisherId) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These rows are the ones where the value of `ISSNs` from `articles_sub` does not\n",
    "exist in `journals_sub`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other join types\n",
    "\n",
    "The pandas `merge` function supports two other join types:\n",
    "\n",
    "* Right (outer) join: Invoked by passing `how='right'` as an argument. Similar\n",
    "  to a left join, except *all* rows from the *right* DataFrame are kept, while\n",
    "  rows from the *left* DataFrame without matching join key(s) values are\n",
    "  discarded.\n",
    "* Full (outer) join: Invoked by passing `how='outer'` as an argument. This join\n",
    "  type returns the all pairwise combinations of rows from both DataFrames; i.e.,\n",
    "  the result DataFrame will `NaN` where data is missing in one of the DataFrames.\n",
    "  This join type is very rarely used.\n",
    "\n",
    "> ## Challenge 1\n",
    "> Create a new DataFrame by joining the contents of the `articles.csv` and\n",
    "> `journals.csv` tables. Are there any records with do not have `ISSNs` code?\n",
    "{: .challenge}\n",
    "\n",
    "> ## Challenge 2\n",
    ">\n",
    "> The `publishers.csv` contains data the names of the publishers for each\n",
    "> journal. Create a DataFrame which also joins this data.\n",
    "{: .challenge}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credits \n",
    "Meterials based on the excellent https://datacarpentry.org/\n",
    "\n",
    "Other Sources:\n",
    "- https://blog.codinghorror.com/a-visual-explanation-of-sql-joins/\n",
    "- Conversations with the wise Kevin Crook https://www.kevincrook.com/ \n",
    "- https://alexpetralia.com/posts/2017/7/19/more-dangerous-subtleties-of-joins-in-sql\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2dae7b8263cf48ae2a1e3e9322b329ad42c2d28af1ff5f49870594264262771"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('data-train': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
